{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # Used for data manipulation and analysis\n",
    "import numpy as np  # Used for numerical operations and array handling\n",
    "import matplotlib.pyplot as plt  # Used for data visualization\n",
    "\n",
    "# Import scikit-learn utilities for preprocessing and model evaluation\n",
    "from sklearn.preprocessing import LabelEncoder  # Encodes target labels with value between 0 and n_classes-1\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold  # Splits data into training and testing sets, and provides cross-validation with stratified folds\n",
    "from sklearn.utils.class_weight import compute_class_weight  # Computes class weights to handle class imbalance\n",
    "\n",
    "# Import necessary Keras modules for deep learning model building and training\n",
    "from tensorflow.keras.models import Sequential  # Used to initialize a sequential model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization  # Common layers used in Convolutional Neural Networks (CNN)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Generates batches of tensor image data with real-time data augmentation\n",
    "from tensorflow.keras.utils import to_categorical  # Converts a class vector (integers) to binary class matrix for use with categorical cross-entropy loss\n",
    "from tensorflow.keras.optimizers import Adam  # Adam optimizer for training the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau  # Callbacks to stop training early and reduce learning rate on plateau\n",
    "\n",
    "# Import pydicom for handling DICOM images, commonly used in medical imaging\n",
    "import pydicom  # Used to read and process DICOM files, the standard format for medical imaging data\n",
    "import os  # Provides a way of using operating system dependent functionality such as reading files from the directory\n",
    "import concurrent.futures  # Provides a high-level interface for asynchronously executing callables\n",
    "\n",
    "# Import l2 regularizer to prevent overfitting by adding a penalty to the loss function based on the weights\n",
    "from tensorflow.keras.regularizers import l2  # Adds L2 regularization to layers to reduce model overfitting risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the CSV files\n",
    "train_labels_df = pd.read_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//train_labels.csv')\n",
    "test_labels_df = pd.read_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels DataFrame:\n",
      "label\n",
      "1550325930    192\n",
      "47603740      176\n",
      "1931643682    176\n",
      "56020246      176\n",
      "2853044871    176\n",
      "             ... \n",
      "2972736368      8\n",
      "1341167394      7\n",
      "2518174510      7\n",
      "2689348626      6\n",
      "983684394       5\n",
      "Name: count, Length: 6294, dtype: int64\n",
      "\n",
      "Test Labels DataFrame:\n",
      "label\n",
      "3481971518    47\n",
      "2828203845    25\n",
      "3844393089    25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for unique labels and their distribution in the training and testing datasets\n",
    "print(\"Train Labels DataFrame:\")\n",
    "# Display the count of each unique label in the training dataset\n",
    "# This helps to understand the class distribution and identify any imbalance in the data\n",
    "print(train_labels_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nTest Labels DataFrame:\")\n",
    "# Display the count of each unique label in the testing dataset\n",
    "# Understanding the test set distribution is crucial for evaluating model performance on unseen data\n",
    "print(test_labels_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the other data files\n",
    "train = pd.read_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//train.csv')\n",
    "train_label_coordinates = pd.read_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//train_label_coordinates.csv')\n",
    "train_series_descriptions = pd.read_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//train_series_descriptions.csv')\n",
    "test_series_descriptions = pd.read_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//test_series_descriptions.csv')\n",
    "sample_submission = pd.read_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\3195464869.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[column].fillna(train[column].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id spinal_canal_stenosis_l1_l2 spinal_canal_stenosis_l2_l3  \\\n",
       "0   4003253                 Normal/Mild                 Normal/Mild   \n",
       "1   4646740                 Normal/Mild                 Normal/Mild   \n",
       "2   7143189                 Normal/Mild                 Normal/Mild   \n",
       "3   8785691                 Normal/Mild                 Normal/Mild   \n",
       "4  10728036                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "  spinal_canal_stenosis_l3_l4 spinal_canal_stenosis_l4_l5  \\\n",
       "0                 Normal/Mild                 Normal/Mild   \n",
       "1                    Moderate                      Severe   \n",
       "2                 Normal/Mild                 Normal/Mild   \n",
       "3                 Normal/Mild                 Normal/Mild   \n",
       "4                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "  spinal_canal_stenosis_l5_s1 left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                 Normal/Mild                           Normal/Mild   \n",
       "1                 Normal/Mild                           Normal/Mild   \n",
       "2                 Normal/Mild                           Normal/Mild   \n",
       "3                 Normal/Mild                           Normal/Mild   \n",
       "4                 Normal/Mild                           Normal/Mild   \n",
       "\n",
       "  left_neural_foraminal_narrowing_l2_l3 left_neural_foraminal_narrowing_l3_l4  \\\n",
       "0                           Normal/Mild                           Normal/Mild   \n",
       "1                           Normal/Mild                           Normal/Mild   \n",
       "2                           Normal/Mild                           Normal/Mild   \n",
       "3                           Normal/Mild                           Normal/Mild   \n",
       "4                           Normal/Mild                           Normal/Mild   \n",
       "\n",
       "  left_neural_foraminal_narrowing_l4_l5  ... left_subarticular_stenosis_l1_l2  \\\n",
       "0                              Moderate  ...                      Normal/Mild   \n",
       "1                              Moderate  ...                      Normal/Mild   \n",
       "2                           Normal/Mild  ...                      Normal/Mild   \n",
       "3                              Moderate  ...                      Normal/Mild   \n",
       "4                           Normal/Mild  ...                      Normal/Mild   \n",
       "\n",
       "  left_subarticular_stenosis_l2_l3 left_subarticular_stenosis_l3_l4  \\\n",
       "0                      Normal/Mild                      Normal/Mild   \n",
       "1                      Normal/Mild                      Normal/Mild   \n",
       "2                      Normal/Mild                      Normal/Mild   \n",
       "3                      Normal/Mild                      Normal/Mild   \n",
       "4                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "  left_subarticular_stenosis_l4_l5 left_subarticular_stenosis_l5_s1  \\\n",
       "0                         Moderate                      Normal/Mild   \n",
       "1                           Severe                      Normal/Mild   \n",
       "2                      Normal/Mild                      Normal/Mild   \n",
       "3                      Normal/Mild                      Normal/Mild   \n",
       "4                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "  right_subarticular_stenosis_l1_l2 right_subarticular_stenosis_l2_l3  \\\n",
       "0                       Normal/Mild                       Normal/Mild   \n",
       "1                       Normal/Mild                          Moderate   \n",
       "2                       Normal/Mild                       Normal/Mild   \n",
       "3                       Normal/Mild                       Normal/Mild   \n",
       "4                       Normal/Mild                       Normal/Mild   \n",
       "\n",
       "  right_subarticular_stenosis_l3_l4 right_subarticular_stenosis_l4_l5  \\\n",
       "0                       Normal/Mild                       Normal/Mild   \n",
       "1                          Moderate                          Moderate   \n",
       "2                       Normal/Mild                       Normal/Mild   \n",
       "3                       Normal/Mild                       Normal/Mild   \n",
       "4                       Normal/Mild                          Moderate   \n",
       "\n",
       "  right_subarticular_stenosis_l5_s1  \n",
       "0                       Normal/Mild  \n",
       "1                       Normal/Mild  \n",
       "2                       Normal/Mild  \n",
       "3                       Normal/Mild  \n",
       "4                       Normal/Mild  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing data in the training DataFrame\n",
    "for column in train.columns:\n",
    "    # To Check if there are missing values in the column\n",
    "    if train[column].isnull().sum() > 0:\n",
    "        # If the column is categorical (dtype 'object'), fill missing values with the mode (most frequent value)\n",
    "        if train[column].dtype == 'object':  \n",
    "            train[column].fillna(train[column].mode()[0], inplace=True)\n",
    "        else:  # If the column is numerical, fill missing values with the mean of the column\n",
    "            train[column].fillna(train[column].mean(), inplace=True)\n",
    "\n",
    "# Convert columns with categorical data to 'category' dtype to optimize memory usage and facilitate encoding\n",
    "categorical_columns = train.select_dtypes(include=['object']).columns\n",
    "train[categorical_columns] = train[categorical_columns].astype('category')\n",
    "\n",
    "# Define a mapping for severity levels to convert ordinal data into numerical form\n",
    "severity_mapping = {\n",
    "    'Mild': 1,        # Mild severity is mapped to 1\n",
    "    'Moderate': 2,    # Moderate severity is mapped to 2\n",
    "    'Severe': 3       # Severe severity is mapped to 3\n",
    "}\n",
    "\n",
    "# Apply severity mapping to any columns containing the ordinal severity levels\n",
    "for col in train.columns:\n",
    "    # Check if the column values match the severity labels, ensuring it's an ordinal column\n",
    "    if set(train[col].dropna().unique()) <= {'Mild', 'Moderate', 'Severe'}:\n",
    "        train[col] = train[col].map(severity_mapping)  # Apply the mapping to convert to numerical values\n",
    "\n",
    "# Display the first few rows of the modified DataFrame to check changes\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows from each DataFrame to ensure data quality\n",
    "train.drop_duplicates(inplace=True)  # Removes duplicate entries from the training data\n",
    "train_label_coordinates.drop_duplicates(inplace=True)  # Removes duplicates from the label coordinates data\n",
    "train_series_descriptions.drop_duplicates(inplace=True)  # Removes duplicates from the series descriptions of the training set\n",
    "test_series_descriptions.drop_duplicates(inplace=True)  # Removes duplicates from the series descriptions of the test set\n",
    "\n",
    "# Save the cleaned DataFrames to CSV files for further analysis or training\n",
    "# Saving the cleaned data helps preserve the preprocessing steps and allows easy access for model training and evaluation\n",
    "train.to_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//cleaned_train.csv', index=False)\n",
    "train_label_coordinates.to_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//cleaned_train_label_coordinates.csv', index=False)\n",
    "train_series_descriptions.to_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//cleaned_train_series_descriptions.csv', index=False)\n",
    "test_series_descriptions.to_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//cleaned_test_series_descriptions.csv', index=False)\n",
    "sample_submission.to_csv('D://rsna//rsna-2024-lumbar-spine-degenerative-classification//cleaned_sample_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_16844\\1996774937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n"
     ]
    }
   ],
   "source": [
    "# Define the relevant columns related to spinal data\n",
    "# Selecting columns that contain terms like 'stenosis' or 'narrowing' \n",
    "# which are critical for diagnosing degenerative spinal conditions\n",
    "spinal_columns = [col for col in train.columns if 'stenosis' in col or 'narrowing' in col]\n",
    "\n",
    "# Prepare features (X) and labels (y)\n",
    "# Features (X) include all columns except 'study_id' which is an identifier not needed for modeling\n",
    "X = train.drop(columns=['study_id'])\n",
    "# Labels (y) are specific spinal condition columns identified above, which will be used as target variables\n",
    "y = train[spinal_columns]\n",
    "\n",
    "# Encode labels using LabelEncoder to convert categorical labels into numerical form\n",
    "label_encoders = {}  # Dictionary to store label encoders for each column, useful for decoding later\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()  # Initialize a label encoder for each column\n",
    "    y[column] = le.fit_transform(y[column])  # Transform the categorical values into numeric form\n",
    "    label_encoders[column] = le  # Store the label encoder for potential inverse transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and resize a DICOM image\n",
    "def read_dicom(file_path, target_size):\n",
    "    # Read the DICOM file using pydicom\n",
    "    dicom = pydicom.dcmread(file_path)\n",
    "    # Extract the pixel array (image data) from the DICOM file\n",
    "    image = dicom.pixel_array\n",
    "    # Resize the image to the specified target size (e.g., 300x300)\n",
    "    image = np.resize(image, target_size)\n",
    "    return image\n",
    "\n",
    "# Function to load DICOM images in parallel with optional label handling\n",
    "def load_dicom_images_parallel(directory, labels_file=None, target_size=(300, 300), limit=None):\n",
    "    images = []  # List to store the loaded images\n",
    "    labels = []  # List to store the corresponding labels\n",
    "    label_map = {}  # Dictionary to map file names to labels\n",
    "\n",
    "    # Load labels if a label file is provided\n",
    "    if labels_file:\n",
    "        labels_df = pd.read_csv(labels_file)  # Read the labels file as a DataFrame\n",
    "        \n",
    "        # Create a mapping of file names to their corresponding labels\n",
    "        for idx, row in labels_df.iterrows():\n",
    "            label_map[row['file_name']] = row['label']\n",
    "\n",
    "    file_paths = []  # List to store paths of DICOM files\n",
    "    # Walk through the directory to find all DICOM files\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.dcm'):  # Check if the file is a DICOM file\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                file_paths.append(file_path)\n",
    "\n",
    "    # Limit the number of files to load, if specified\n",
    "    if limit:\n",
    "        file_paths = file_paths[:limit]\n",
    "\n",
    "    # Load images in parallel using ThreadPoolExecutor for faster processing\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks to the executor, creating a future for each file to be processed\n",
    "        futures = {executor.submit(read_dicom, file_path, target_size): file_path for file_path in file_paths}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            file_path = futures[future]\n",
    "            try:\n",
    "                # Retrieve the processed image from the future\n",
    "                image = future.result()\n",
    "                images.append(image)  # Add the image to the list of images\n",
    "                file_name = os.path.basename(file_path)  # Extract the file name from the path\n",
    "                \n",
    "                # Retrieve the label from the label_map if available\n",
    "                if file_name in label_map:\n",
    "                    label = label_map[file_name]\n",
    "                else:\n",
    "                    label = -1  # Use -1 as a fallback value for missing labels\n",
    "                    print(f\"Warning: No label found for {file_name}. Assigning default label {label}.\")\n",
    "                \n",
    "                labels.append(label)  # Add the label to the list of labels\n",
    "            except Exception as exc:\n",
    "                # Handle exceptions that occur during image processing\n",
    "                print(f'{file_path} generated an exception: {exc}')\n",
    "    \n",
    "    # Return the loaded images and labels as NumPy arrays\n",
    "    return np.array(images), np.array(labels)\n",
    "    print(np.array(images), np.array(labels))  # Print statement to visualize arrays (Note: this line is after the return, so it won't execute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images and their corresponding labels\n",
    "train_images, train_image_labels = load_dicom_images_parallel(\n",
    "    'D://rsna//rsna-2024-lumbar-spine-degenerative-classification//train_images',  # Directory containing training DICOM images\n",
    "    labels_file='D://rsna//rsna-2024-lumbar-spine-degenerative-classification//train_labels.csv',  # CSV file containing labels for the training images\n",
    "    limit=10000  # Limit the number of images to load (e.g., for memory or speed considerations)\n",
    ")\n",
    "\n",
    "# Load test images and their corresponding labels\n",
    "test_images, test_image_labels = load_dicom_images_parallel(\n",
    "    'D://rsna//rsna-2024-lumbar-spine-degenerative-classification//test_images',  # Directory containing test DICOM images\n",
    "    labels_file='D://rsna//rsna-2024-lumbar-spine-degenerative-classification//test_labels.csv',  # CSV file containing labels for the test images\n",
    "    limit=1000  # Limit the number of images to load\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the loaded training data is not empty\n",
    "if train_images.size == 0 or train_image_labels.size == 0:\n",
    "    print(\"Error: No training images or labels found.\")  # Print error if training images or labels are empty\n",
    "\n",
    "# Verify that the loaded test data is not empty\n",
    "if test_images.size == 0 or test_image_labels.size == 0:\n",
    "    print(\"Error: No test images or labels found.\")  # Print error if test images or labels are empty\n",
    "\n",
    "# Additional check: Raise an exception if training labels are empty to stop further processing\n",
    "if len(train_image_labels) == 0:\n",
    "    raise ValueError(\"train_image_labels array is empty.\")  # Raise an error to ensure no empty labels go unnoticed\n",
    "\n",
    "# Additional check: Raise an exception if test labels are empty to stop further processing\n",
    "if len(test_image_labels) == 0:\n",
    "    raise ValueError(\"test_image_labels array is empty.\")  # Raise an error to prevent training with missing test labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap labels to a reasonable value to handle any outliers or erroneous values\n",
    "# Setting a maximum value for the labels helps in controlling the range of target values, ensuring consistent class boundaries\n",
    "max_reasonable_value = 10  # Define the maximum reasonable label value based on the dataset specifics\n",
    "\n",
    "# Apply capping to the training labels using np.clip, which limits values between 0 and max_reasonable_value\n",
    "train_image_labels = np.clip(train_image_labels, 0, max_reasonable_value)\n",
    "\n",
    "# Apply capping to the test labels similarly\n",
    "test_image_labels = np.clip(test_image_labels, 0, max_reasonable_value)\n",
    "\n",
    "# Determine the number of classes for the classification task\n",
    "# This calculates the maximum label value from both training and test labels, then adds 1 (for zero-indexing)\n",
    "num_classes = max(train_image_labels.max(), test_image_labels.max()) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channel dimension to the images\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# Normalize images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_image_labels = to_categorical(train_image_labels, num_classes=num_classes)\n",
    "test_image_labels = to_categorical(test_image_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srira\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape based on your image data dimensions\n",
    "# Here, the images are assumed to be grayscale (hence '1' in the third dimension) with 300x300 pixels\n",
    "input_shape = (300, 300, 1)  # Adjust based on actual image size and number of channels\n",
    "\n",
    "# Define the number of classes based on capped label values plus one for zero indexing\n",
    "num_classes = 11  # Update this value based on the actual number of distinct classes\n",
    "\n",
    "# Define the Convolutional Neural Network model\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer with increased l2 regularization to reduce overfitting\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Pooling layer to reduce spatial dimensions\n",
    "model.add(BatchNormalization())  # Normalization to improve training stability\n",
    "model.add(Dropout(0.7))  # Increased dropout rate for regularization\n",
    "\n",
    "# Second convolutional layer with increased l2 regularization\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Pooling layer to further reduce spatial dimensions\n",
    "model.add(BatchNormalization())  # Normalization layer\n",
    "model.add(Dropout(0.7))  # Dropout to further prevent overfitting\n",
    "\n",
    "# Flattening the output to feed into the fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layer with increased l2 regularization and ReLU activation\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.7))  # High dropout rate to promote robust feature learning\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation configuration to artificially increase the diversity of the training dataset\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,           # Randomly rotate images by up to 30 degrees\n",
    "    width_shift_range=0.2,       # Randomly shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2,      # Randomly shift images vertically by up to 20% of the height\n",
    "    shear_range=0.2,             # Apply shear transformation with a shear intensity of up to 20%\n",
    "    zoom_range=0.2,              # Randomly zoom into images by up to 20%\n",
    "    horizontal_flip=True,        # Randomly flip images horizontally\n",
    "    fill_mode='nearest'          # Filling strategy for new pixels generated during transformations\n",
    ")\n",
    "\n",
    "# Early stopping callback to prevent overfitting by stopping training when validation loss stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',          # Monitor validation loss to determine when to stop\n",
    "    patience=3,                  # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True    # Restore model weights from the epoch with the best validation loss\n",
    ")\n",
    "\n",
    "# Reduce learning rate on plateau callback to dynamically adjust learning rate during training\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',          # Monitor validation loss to trigger learning rate reduction\n",
    "    factor=0.2,                  # Factor by which the learning rate will be reduced (new_lr = lr * factor)\n",
    "    patience=2,                  # Number of epochs with no improvement before reducing the learning rate\n",
    "    min_lr=0.0001                # Minimum learning rate to avoid excessively small learning rates\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srira\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 2s/step - accuracy: 0.9159 - loss: 22.1183 - val_accuracy: 1.0000 - val_loss: 17.2653 - learning_rate: 0.0010\n",
      "Epoch 2/3\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - accuracy: 0.9926 - loss: 16.5121 - val_accuracy: 1.0000 - val_loss: 13.2778 - learning_rate: 0.0010\n",
      "Epoch 3/3\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - accuracy: 0.9916 - loss: 15.6774 - val_accuracy: 1.0000 - val_loss: 16.8545 - learning_rate: 0.0010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 13.2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">149</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">341056</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">43,655,296</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m298\u001b[0m, \u001b[38;5;34m298\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m149\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m147\u001b[0m, \u001b[38;5;34m147\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m73\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m341056\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m43,655,296\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)                  │           \u001b[38;5;34m1,419\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,027,363</span> (499.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,027,363\u001b[0m (499.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,675,723</span> (166.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,675,723\u001b[0m (166.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,351,448</span> (333.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m87,351,448\u001b[0m (333.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "# Using stratified split to ensure each class is proportionally represented in both training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_images,               # Input images from the training set\n",
    "    train_image_labels,         # Corresponding labels for the input images\n",
    "    test_size=0.3,              # 30% of the data will be used for validation\n",
    "    random_state=42,            # Seed for reproducibility\n",
    "    stratify=train_image_labels # Ensures the split maintains the distribution of labels\n",
    ")\n",
    "\n",
    "# Train the model using augmented data from the ImageDataGenerator\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),  # Augmented training data with batch size of 32\n",
    "    epochs=3,                                      # Number of training epochs\n",
    "    validation_data=(X_val, y_val),                # Validation data to monitor performance during training\n",
    "    callbacks=[early_stopping, reduce_lr]          # Use early stopping and learning rate reduction callbacks\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set to assess generalization performance\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_image_labels)\n",
    "print(f'Test accuracy: {test_accuracy}')  # Print the accuracy on the test data\n",
    "\n",
    "# Save the trained model to an HDF5 file for future use\n",
    "model.save('spine_degenerative_cnn_model.h5')\n",
    "\n",
    "# Print a summary of the model architecture, including layers, shapes, and parameter counts\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot training and validation performance metrics\n",
    "def plot_performance(history):\n",
    "    # Set up the figure size for the plots\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot training and validation accuracy over epochs\n",
    "    plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')  # Plot training accuracy\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')  # Plot validation accuracy\n",
    "    plt.xlabel('Epoch')  # Label for the x-axis\n",
    "    plt.ylabel('Accuracy')  # Label for the y-axis\n",
    "    plt.ylim([0, 1])  # Set y-axis limits from 0 to 1 (percentage scale)\n",
    "    plt.legend(loc='lower right')  # Place the legend in the lower right corner\n",
    "    \n",
    "    # Plot training and validation loss over epochs\n",
    "    plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
    "    plt.plot(history.history['loss'], label='Loss')  # Plot training loss\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')  # Plot validation loss\n",
    "    plt.xlabel('Epoch')  # Label for the x-axis\n",
    "    plt.ylabel('Loss')  # Label for the y-axis\n",
    "    plt.ylim([0, 1])  # Set y-axis limits from 0 to 1\n",
    "    plt.legend(loc='upper right')  # Place the legend in the upper right corner\n",
    "    \n",
    "    # Display the plots\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the performance of the model\n",
    "plot_performance(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
