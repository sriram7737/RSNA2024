# RSNA2024

# Team: Nathan Pham, Sriram Rampelli, Priyatham Chadalawada


The automated identification of anomalies in spinal imaging, namely neural foraminal constriction and spinal canal stenosis, was the main emphasis of the RSNA competition. This required processing and analyzing a large set of DICOM images, where the primary goal was to classify spine conditions as normal, moderate, or severe. Convolutional neural networks (CNNs) and using Dense Neural Networks which in this case, we used DNN for Model 1, a type of deep learning model, were employed by our team to extract characteristics from the DICOM pictures. To guarantee consistency, we performed specialized preparation operations such as data normalization and scaling. The different sizes and levels of complexity in the photos made the dataset difficult to work with, but with careful treatment of this heterogeneity, we were able to train a reliable model.

Our group was able to extract important metadata from the spinal investigations and load and handle the large-scale DICOM pictures in an organized manner utilizing the code that was built. This was especially crucial because managing numerous target labels for every spinal segment was required for the competition. With distinct mappings between the photos and their labels, the technology also allowed the team to effectively produce and manage many classes of anomalies. Achieving a high validation accuracy of over 95% was largely due to the deployment of multi-class classification, picture warping for model input, and image normalization. Additionally, we learnt how to fine-tune the classification through training optimization utilizing cross-entropy loss and adaptive learning rates.

Our team learned a great deal about handling the complexity of DICOM formats and working with medical imaging data as a result of this approach. They also gained knowledge on how to create scalable and effective pipelines for big datasets while striking a balance between model complexity and accuracy. The process also demonstrated the value of careful data preprocessing, wise model architecture choices, and ongoing performance tracking using metrics like classification reports and confusion matrices, which were essential in determining the model's strengths and areas for development.

Improving the model's performance using more sophisticated designs, such convolutional neural networks (CNNs) made especially for medical picture processing, would be one area of focus for future research. Better feature extraction and more precise predictions may result from this, especially when it comes to recognizing subtle variations in spinal disorders. Furthermore, adding more varied datasets from other healthcare facilities could enhance the model's generalizability across a range of imaging devices and patient types. Using transfer learning techniques on medical imaging tasks using pre-trained models is another possible avenue to speed up training and maybe improve performance.

The present model's primary drawback is its exclusive focus on a single deep learning architecture, with no consideration given to ensemble techniques. Combining the predictions from several models into an ensemble might lower variation and increase the findings' resilience. Another drawback is that, despite the model's high accuracy, it could not be enough for clinical applications where incorrect categorization could result in unsuitable treatment choices. To make this model work in a real-world healthcare context, it is imperative to improve the precision and recall for all categories, especially the more severe instances.

The dataset itself also presents difficulties because labeling is based on human annotations, which might bring errors and irregularities. This is particularly important for medical datasets, since even small mislabeling can result in large model mistakes. To fully realize the potential of the proposed model, these issues would need to be addressed by improved data curation, automated labeling methods, or larger datasets.
